                        SPLEX
Statistiques pour la classification et fouille de donneÌes
                     en geÌnomique
                   Apprentissage statistique



                   Pierre-Henri WUILLEMIN

                        Decision-axe IA-LIP6
                  pierre-henri.wuillemin@lip6.fr
   Quelques points dâ€™organisation



    â€¢ Intervenants en cours : Nataliya Sokolovska, Pierre-Henri Wuillemin


    â€¢ TME en python (Nataliya Sokolovska)


    â€¢ Cours (55â€“65 201bis) â€“ TME (14â€“15 509)


    â€¢ EÌvaluation : 2 examens reÌpartis (70%=35%+35%), une note de TME (30%)




SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique   Apprentissage statistique   2 / 48
   Un (tout petit) peu dâ€™histoire
                    La classification est un theÌ€me majeur de lâ€™histoire de la biologie.

     Andreas Caesalpinus (CeÌsalpin),
    De plantis libri XVI, Florence, 1583 : PremieÌ€re taxonomie.




      Buffon, 1749
                â‰ª  Le seul moyen de faire une meÌthode instructive et naturelle est
                de mettre ensemble les choses qui se ressemblent et de seÌparer
                celles qui diffeÌ€rent les unes des autres. â‰«

      XIXeÌ€me sieÌ€cle : TheÌorie statistique
                                QueÌtelet (1796â€“1874)
                                Recensement ameÌricain, 1890 (utilisation de la carte perforeÌe).

      XXeÌ€me sieÌ€cle : Analyse de donneÌes, apprentissage statistique
SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique   Apprentissage statistique   3 / 48
   Quel est le probleÌ€me ?

    Description de la taÌ‚che de classification
             Identifier la classe dâ€™appartenance des objets aÌ€ partir de certains de leurs
             attributs (features),
             Attribuer une classe aÌ€ un objet aÌ€ partir de ces attributs.


    Buts de la classification
             Connaissance (apprentissage) de la structure des ensembles dâ€™objets
             Processus de deÌcisions automatiques


    Applications
             Diagnostic meÌdical                                                 ControÌ‚le de process
             PreÌ‚t bancaire, Marketing                                           Reconnaissance de formes
                               (profiling)                                                (pattern recognition)
             Fusion de senseurs                                                  etc.

SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique    Apprentissage statistique       4 / 48
   Analyse de donneÌes et Data Mining

    â½ DeÌfinition (Analyse de donneÌes)
    Ensemble de meÌthodes dâ€™explorations de donneÌes consideÌreÌes comme des points
    dans un espace vectoriel multi-dimensionnel.
    Par exemple : Analyse en Composantes Principales (ACP), reÌgression lineÌaire, etc.

    â½ DeÌfinition (Data Mining)
    Organisation et exploration de donneÌes consideÌreÌes comme des points dans un
    espace vectoriel multi-dimensionnel dans le but dâ€™apprendre une structure ou
    dâ€™apprendre aÌ€ preÌdire.

             PreÌdire : apprentissage par lâ€™exemple afin de mimer un comportement.
                     Discrimination,
                     ReÌgression,
                     Classification superviseÌe, etc.
             Apprendre une structure : extraire de lâ€™information.
                     Classification non superviseÌe,
                     DeÌtection de motifs, etc.
SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique   Apprentissage statistique   5 / 48
   Formalisation
        Soit Î  une population (un ensemble dâ€™objets),
        chaque eÌleÌment de Î  est deÌtermineÌ par d attributs (supposeÌment
        quantitatifs). On nomme D âŠ† Rd lâ€™espace descriptif,
        chaque eÌleÌment de Î  appartient aÌ€ une classe de C.
    Autrement dit,
    Relations fonctionnelles
    âˆƒD : Î  â†’ D et C : Î  â†’ C telles que âˆ€Ï€ âˆˆ Î ,                                                                                 Î 


             D(Ï€) est le vecteur des attributs deÌterminant Ï€,                                                       D(.)           C (.)


             C (Ï€) est la classe de Ï€.                                                                               D                 C


    On ne connait en fait un objet Ï€ que par lâ€™intermeÌdiaire de sa description D(Ï€).

    TaÌ‚che de classification
                                                                                                                     Î 
    Trouver Cb : D â†’ C telle que
                                                                                                             D(.)           C (.)
         âˆ€Ï€, Cb (D(Ï€)) â‰ˆ C (Ï€) avec â€œle moins dâ€™erreur possibleâ€
    C est appeleÌ le classifieur.
    b                                                                                                        D
                                                                                                                    Cb(.)
                                                                                                                               C


SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique   Apprentissage statistique                                  6 / 48
                                                                                                                     Î 

   Trouver Cb : meÌthodologie en mode superviseÌ                                                             D(.)           C (.)


    On suppose que D, C et D sont parfaitement connus mais pas C .                                           D                 C
                                                                                                                    Cb(.)

      1   Apprentissage sur un base dâ€™exemples
    Soit Î a âŠ‚ Î  pour lequel on connait parfaitement la restriction C|Î a ,
                            on peut alors estimer Cb sur Î a .
      2   Validation sur un base dâ€™exemples
    Soit Î v âŠ‚ Î  \ Î a pour lequel on connait parfaitement la restriction C|Î v ,
         On peut alors eÌvaluer Cb sur Î v et construire des indicateurs de qualiteÌ.
      3   PreÌdiction
    âˆ€Ï€ âˆˆ Î  \ (Î a âˆª Î v ), on ne connait pas C (Ï€) : on le preÌdit par Cb(D(Ï€)).

                Nature des donneÌes
                Chaque donneÌe (D, Î a , C|Î a , Î v , C|Î v ,) peut eÌ‚tre fausse, bruiteÌe,
                incompleÌ€te, non indeÌpendante, etc.
                Lâ€™estimation est une approximation et la construction de lâ€™estimateur peut
                eÌ‚tre une heuristique !
SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique   Apprentissage statistique                  7 / 48
   Simplifier les notations
    GeÌneÌralement, le probleÌ€me de classification prendra la forme suivante :
             Soit une v.a. X (de dimension d) aÌ€ valeurs dans R (D = Rd ),
                                                                                     discreÌ€te (classification : C âŠ‚ Z)
             Soit une v.a. Y (de dimension 1)
                                                                                     continue (reÌgression : C âŠ† R).
             Î a âˆª Î v est une base de N observations (Xi , Yi ) de ces variables.
                   2
               X                                                                 Î 


                                                                      D(.)            C (.)                                 D(Ï€)            C (Ï€)
                       X1
                                                                                                             Ï€1           X11         X12   Y1
                                                                       D                 C                   Ï€2           X21         X22   Y2
                                                                                                             Ï€3           X31         X32   Y3
                                        X2
                                                                                                             Â·Â·Â·                Â·Â·Â·         Â·Â·Â·
                                                                                                             Ï€n           XN1         XN2   YN

                                                         1
                                                     X
                             XN




    Le probleÌ€me de la classification (et de la reÌgression)
                   Soit x une instantiation de X , quelle valeur prendrait y = Cb(x) ?

SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique                Apprentissage statistique                             8 / 48
   Deux approches de la classification superviseÌe

    Approches non parameÌtriques
             Pas dâ€™hypotheÌ€se sur le modeÌ€le des donneÌes,
             Seuls les exemples meÌ€nent vers Cb.
    Exemple : meÌthode des k plus proches voisins, feneÌ‚tre de Parzen.


    Approches parameÌtriques
             AÌ€ partir de lâ€™hypotheÌ€se forte de lâ€™existence dâ€™un modeÌ€le,
             Phase dâ€™estimation des parameÌ€tres du modeÌ€le : Î˜,  b
             Cb est alors Cbb .      Î˜
    Exemple : ReÌgression, Classification bayeÌsienne

    Pour la suite du cours (sauf si preÌciseÌ), on simplifiera la taÌ‚che de classification aÌ€ la
    discrimination entre 2 classes seulement : Y peut prendre les valeurs âˆ’1 et 1.
    Le classifieur Cb se deÌcompose alors en 2 fonctions : g : Rd â†’ R et Cb = Ïƒ(g ).

SPLEX Statistiques pour la classification et fouille de donneÌes en geÌnomique   Apprentissage statistique   9 / 48
             EÌvaluations et Comparaisons de Classifieurs




EÌvaluations et Comparaisons de Classifieurs                10 / 48
EÌvaluation dâ€™un classifieur
Quelles proprieÌteÌs peut-on demander pour Cb ?

CriteÌ€re : preÌcision
Un classifieur doit minimiser le taux dâ€™erreur lors de son utilisation. ( ?)


CriteÌ€re : compreÌhensibiliteÌ
Un classifieur repreÌsentant une base doit eÌ‚tre intelligible :
      expliquable (et donc exploitable),
      compreÌhensible (par un expert),
      parameÌ€trable (par un expert).


CriteÌ€re : rapiditeÌ
Les opeÌrations sur le classifieur doivent eÌ‚tre faciliteÌes.
      Construction aiseÌe,
      Mise aÌ€ jour aiseÌe (increÌmentale),
      CriteÌ€re de classification rapide.
   EÌvaluations et Comparaisons de Classifieurs                                11 / 48
MeÌthodologie

                                                                                          algo i




                                             Apprentissage
                                                                    Î a
                                                                                        Cbi
                                                                    Î v
                                                                           Validation
     Base




                                                                                        Cbâˆ—
                                                             Test



                                                                     Evaluation



  EÌvaluations et Comparaisons de Classifieurs                                                12 / 48
DiffeÌrents classifieurs




  EÌvaluations et Comparaisons de Classifieurs   13 / 48
EÌvaluation de Cb
                                Ce quâ€™on voudrait connaÄ±Ì‚tre, câ€™est lâ€™erreur que lâ€™on fera en utilisant Cb au lieu de C .
           Î 


 D(.)            C (.)          Erreur en geÌneÌralisation
                                                                                    
  D
         Cb(.)
                    C
                                                            e(Cb) = Ex C (x) Ì¸= Cb(x)

En reÌgression, on utilisera plutoÌ‚t la distance quadratique :
                                                                               2
                                                     e(Cb) = Ex    C (x) âˆ’ Cb(x)



Toutefois, cette erreur en geÌneÌralisation nâ€™est pas atteignable. Il faut donc lâ€™estimer.


Erreur en apprentissage, erreur en validation
                          P                                                                 P                        
ea (Cb) = âˆ¥Î 1a âˆ¥              xâˆˆÎ a Î´          C (x) âˆ’ Cb(x)                ev (Cb) = âˆ¥Î 1v âˆ¥   xâˆˆÎ v Î´       C (x) âˆ’ Cb(x)
                                                                   
                                                                       1    si x Ì¸= 0
                                                      ouÌ€ Î´(x) =
                                                                       0    si x = 0


Mais ces erreurs expeÌrimentales nâ€™indiquent a priori rien dâ€™autres que des hypotheÌ€ses sur e(Cb).

      EÌvaluations et Comparaisons de Classifieurs                                                                    14 / 48
Erreurs des erreurs de classification
 erreur dâ€™apprentissage                          erreur de test de validation
                                                                     SNv      (v )
                                                                       i=1 {xi     }:
                                SN a      (a)
                                   i=1 {xi } :
 Sur la base Î a =                                Sur la base Î v =

           1 X                                          1 X
              a   N                                      v N                    
                       (a)       (a)                                (v )      (v )
  Ïµa =          Î´ Cb(xi ) âˆ’ C (xi )              Ïµv =        Î´ Cb(xi ) âˆ’ C (xi )
           Na                                           Nv
                  i=1                                       i=1


         On peut rendre Ïµa = 0.                         Ïµv = 0 est treÌ€s deÌpendant de Î v
                                                 (biais, approximation, etc.).

       Cb peut se sur-adapter aÌ€ Î a :                                 Sur-apprentissage
              sur-apprentissage
                                                                                          Ïµv




                                                                                          Ïµa


  EÌvaluations et Comparaisons de Classifieurs                                                 15 / 48
Estimation du taux dâ€™erreur de Cb
Estimation sur Î a
 â—‹
 + Estimation aiseÌe !
 â—‹
 - Sous-estimation eÌvidente
 â—‹
 - Favorise le surapprentissage

Estimation sur Î v
 â—‹
 + Estimation aiseÌe !
 â—‹
 - GaÌ‚chis dâ€™une partie des donneÌes classeÌes
 â—‹
 - DonneÌes issues de la meÌ‚me base que Î a â‡’ risque de biais

Cross-Validation, Leave-one-out, bootstrap
Avec C (Î âˆ— ) bien connu, construire plusieurs Î v diffeÌrents et apprendre sur
Î a = Î âˆ— \ Î v ...
 â—‹
 + Plus de perte de donneÌes,
 â—‹
 + Une certaine robustesse de lâ€™eÌvaluation,
 â—‹
 - Cher et lent ! !
   EÌvaluations et Comparaisons de Classifieurs                                 16 / 48
LOOCV : Leave-One-Out Cross Validation
LOOCV est un algorithme qui permet de se passer de Î v en contre-partie dâ€™un temps de calcul beaucoup plus
important.


                LOOCV
              Data : Î a
            1 for each Ï€ âˆˆ Î a do
            2               âˆ’Ï€ en apprenant sur Î a \ {Ï€}
                  Calculer Cd
            3     eÏ€ = |Câˆ’Ï€ (Ï€) âˆ’ C (Ï€)|
                        d

            4 Calculer C
                       b en apprenant sur Î a
            5 alors
                                             1 X
                             eLOOCV (Cb) =            eÏ€
                                           âˆ¥Î a âˆ¥
                                                          Ï€âˆˆÎ a



Il existe bien eÌvidemment des variantes de cet algorithme, moins gourmands car
utilisant une partition en k sous-ensembles de Î a plutoÌ‚t que dâ€™en isoler chaque
singleton : k-fold Cross Validation.

   EÌvaluations et Comparaisons de Classifieurs                                                    17 / 48
Autres indicateurs sur Î v

Matrice de confusion
Sur une base de test :

                                                  C (x) = â—‹
                                                          -   C (x) = â—‹
                                                                      +
                             Cb(x) = â—‹
                                     -               VN          FN       VN + FN
                             Cb(x) = â—‹
                                     +               FP          VP       VP + FP
                                                  VN + FP     FN + VP       N


Indicateurs
      Taux dâ€™erreur : ev (Cb) = FP+FN
                                  N
      Accuracy (taux de bon classement) : VP+VN
                                            N
                                                VN
      SpeÌcificiteÌ (taux de vrai neÌgatifs) : VN+FP
                                                  FP
      1âˆ’SpeÌcificiteÌ (taux de faux positifs) : VN+FP
                                                      VP
      SensibiliteÌ,Rappel (taux de vrai positifs) : VP+FN
                     VP
      PreÌcision : VP+FP
   EÌvaluations et Comparaisons de Classifieurs                                     18 / 48
CouÌ‚ts dâ€™affectation

Il peut eÌ‚tre inteÌressant de briser la symeÌtrie entre FP et FN.


Matrice dâ€™affectation

                                                        C (x) = â—‹
                                                                -   C (x) = â—‹
                                                                            +
                                      Cb(x) = â—‹
                                              -            0             Î³FN
                                      C (x) = â—‹
                                       b      +           Î³FP             0
 GeÌneÌralement, on privileÌgie les erreurs de premieÌ€re espeÌ€ce : Î³FP â‰« Î³FN



On peut alors deÌfinir un couÌ‚t dâ€™un classifieur :

       Indicateur de couÌ‚t
                                                        FP Â· Î³FP + FN Â· Î³FN
                                           cout(Cb) =
                                                                 N

   EÌvaluations et Comparaisons de Classifieurs                                 19 / 48
Limite des indicateurs issus de la matrice de confusion

                                               c1 â—‹
                                               C   -       â—‹
                                                           +                   c2 â—‹
                                                                               C   -     â—‹
                                                                                         +
Comment comparer                               â—‹
                                               c- 40       10         et       â—‹
                                                                               c- 45       5       ?
                                               â—‹
                                               + 10
                                               c           40                  â—‹
                                                                               + 20
                                                                               c          30

  eV (C
      c1 ) = 0.2 et eV (C
                        c2 ) = 0.25
                                                                                               â‡’C
                                                                                                c1 â‰» C
                                                                                                     c2


                                                       â—‹
                                                       -        â—‹
                                                                +
  Avec la matrice de couÌ‚t : â—‹
                             -
                             c                         0        10 , cout(C
                                                                          c1 ) = 1.1 et cout(C
                                                                                             c2 ) = 0.7
                             â—‹
                             +
                             c                         1        0
                                                                                               â‡’C c1 â‰º Cc2
PS : Comparer eV revient aÌ€ utiliser une matrice de couÌ‚t avec Î³FP = Î³FN = 1.
Doit-on tester pour toutes les matrices de couÌ‚t possible ?
Comment comparer globalement les modeÌ€les sans couÌ‚t ?

    EÌvaluations et Comparaisons de Classifieurs                                                       20 / 48
Cas de classes deÌseÌquilibreÌes

Matrice de confusion â€“ COILâ€™00 â€“ Challenge police dâ€™assurance
                                                   Cb   â—‹
                                                        -      â—‹
                                                               +
                     Sur une base de test :        â—‹
                                                   c-   3731   31
                                                   â—‹
                                                   +
                                                   c     229   9



 eV (Cb) = 229+31
            4000
 eV (Toujours â—‹)
              c- = 31+9              4000                                                       Cb â‰º Toujours â—‹
                                                                                                              -
                                                                                                              c

Au lieu de se limiter aÌ€ des criteÌ€res sur lâ€™affectation proposeÌe, il sâ€™agirait de mesurer la propension aÌ€ eÌ‚tre dans
une classe.
Un classifieur est souvent composeÌ de :
       Une fonction g : D âˆ’â†’ R
       Une fonction Ïƒ : R âˆ’â†’ C (fonction signe si classificateur binaire)



                    Quand Cbi (x) = Ïƒ(gi (x)), il faudrait comparer g1 et g2 ! ! !


    EÌvaluations et Comparaisons de Classifieurs                                                                  21 / 48
Courbe de ROC

Courbe de ROC : Receiver Operating Characteristic
     Outil dâ€™eÌvaluation et de comparaison de classifieurs,
     Outil graphique (aiseÌment lisible),
     IndeÌpendant des matrices de couÌ‚ts,
     Utilisable dans le cas de classes deÌseÌquilibreÌes,
     Indicateur syntheÌtique associeÌ (aiseÌment interpreÌtable).




  EÌvaluations et Comparaisons de Classifieurs                      22 / 48
Construction de la courbe de ROC
Soit Cb(x) = Ïƒ(g (x)).
Soit B> la base des x âˆˆ Î a , classeÌs par valeur croissante de g (x).
On construit alors une famille de classifieurs Cbk , k âˆˆ {0, Â· Â· Â· , |Î a |}, deÌfinis ainsi :

               âˆ€k âˆˆ {0, Â· Â· Â· , |Î a |} , Cbk = {classer â—‹
                                                        - les x de rangâ‰¤k dans B> }

    Rappel :
                                     FP
           1âˆ’SpeÌcificiteÌ (TFP) : VN+FP
                                  VP
           SensibiliteÌ (TVP) : VP+FN             Cb0 : sensibiliteÌ=1 et speÌcificiteÌ=0
                                                  Cb|Î  | : sensibiliteÌ=0 et speÌcificiteÌ=1
                                                      a




   Construction de la courbe de ROC
   âˆ€k âˆˆ {0, Â· Â· Â· , |Î a |}, afficher le point
         (1âˆ’speÌcificiteÌ(Ck ),sensibiliteÌ(Ck ))


   EÌvaluations et Comparaisons de Classifieurs                                                23 / 48
construction de la courbe de ROC (1)




From : Ricco RAKOTOMALALA â€“ Laboratoire ERIC
   EÌvaluations et Comparaisons de Classifieurs   24 / 48
construction de la courbe de ROC (2)




From : Ricco RAKOTOMALALA â€“ Laboratoire ERIC
   EÌvaluations et Comparaisons de Classifieurs   25 / 48
Utilisation de la courbe de ROC (1)
                                                     1   Tout classifieur est un point dans lâ€™espace ROC.
                                                          (0, 1) : Classifieur parfait.
                                                          (1, 1) : Classifieur â€œtoujours â—‹â€.
                                                                                         +
                                                          (0, 0) : Classifieur â€œtoujours â—‹â€.
                                                                                         -
                                                          (q, q) : Classifieur â€œproba(Cb(x) = â—‹)
                                                                                              + = qâ€.
                                                     2 Une famille de classifieurs Cbk doit avoir sa
                                                    courbe de ROC au dessus de la premieÌ€re diagonale
                                                    (x = y ).
                                                    Puisque cette premieÌ€re diagonale correspond aux classifieur
                                                    aleÌatoires.


 3   criteÌ€re AUC Area Under Curve
       Pour la diagonale : AUC = 12
       Pour le test ideÌal, AUC = 1
       Pour un test quelconque, 12 â‰¤ AUC â‰¤ 1. Plus
       il est grand, mieux câ€™est.
AUC indique la probabiliteÌ pour que Cb interclasse un positif et un
neÌgatif.


     EÌvaluations et Comparaisons de Classifieurs                                                                  26 / 48
Utilisation de ROC (2) : comparaison de classifieurs


1  Dominance
Si ROCM1 â‰» ROCM2 alors il ne peut pas exister
de situation (quelque soit le couÌ‚t) ouÌ€ M2 serait
un meilleur classifieur que M1.




2   Enveloppe convexe
Les classifieurs ne participant jamais aÌ€
lâ€™enveloppe convexe sont domineÌs et peuvent
eÌ‚tre eÌlimineÌs.
      M1 domineÌ
      M4 domineÌ par max(M2, M3)


    EÌvaluations et Comparaisons de Classifieurs       27 / 48
                          AggreÌgations de Classifieurs




AggreÌgations de Classifieurs                             28 / 48
Introduction au bootstrap

Principe
ProbleÌ€me : Quelle est la distribution dâ€™un estimateur calculeÌ aÌ€ partir dâ€™un eÌchantillon L ?
Si on connait la distribution de lâ€™eÌchantillon ou si on peut faire lâ€™hypotheÌ€se dâ€™une
distribution gaussienne, pas de probleÌ€mes. Mais sinon ?

But du bootstrap : Remplacer des hypotheÌ€ses probabilistes pas toujours veÌrifieÌes
ou meÌ‚me inveÌrifiables par des simulations et donc beaucoup de calcul.

Exemple : L = {x1 , Â· Â· Â· , xn } suffit aÌ€ calculer xÌ„, estimateur de Âµ.
Comment estimer sa preÌcision (son eÌcart-type) ? son biais ?
                                        2
  1   iid + TCL â‡’ X âˆ¼ N (Âµ, Ïƒn ).
  2   Soit (Lj )jâˆˆJ une famille dâ€™eÌchantillons.
                              â‡’ on peut estimer ces statisiques aÌ€ partir des (xÌ„j )jâˆˆJ .
  3   Soit L lâ€™unique eÌchantillon utilisable â‡’ calculer un ensemble dâ€™eÌchantillons
      bootstrap.

        AggreÌgations de Classifieurs                                                     29 / 48
Bootstrap : points de repeÌ€res


   Bradeley Erfon, 1979. Erfon & Tibshirani, 1993.




   Origine du nom : InspireÌe du baron de MuÌˆnchausen
   (Rudolph Erich Raspe) qui se sortit de sables mouvants
   par traction sur ses tirants de bottes.




   PopulariseÌ avec la monteÌe en puissance de lâ€™ordinateur dans les calculs
   statistiques.
   BaseÌ sur une theÌorie matheÌmatique bien roÌ‚deÌe.



     AggreÌgations de Classifieurs                                             30 / 48
EÌchantillon bootstrap

     General Bootstrap Algorithm
   Data : L eÌchantillon,Î¸ parameÌ€tre aÌ€ estimer sur L,
 1 for b âˆˆ {1, Â· Â· Â· , B} do
 2     Tirer aleÌatoirement Lb , un eÌchantillon avec remise dans L
 3     Estimer Î¸ bb sur lâ€™eÌchantillon Lb

 4        b1 , Â· Â· Â· , Î¸
     Le = Î¸            bB                est un eÌchantillon bootstrap issu de L.


                                                       On peut alors utiliser Le pour estimer des
                                                       statistiques de la distribution de
                                                       lâ€™estimateur de Î¸ :
                                                                          PB b           PB b 2
                                                                b2B = Bâˆ’1
                                                         Ïƒ2Î¸b â‰ˆ Ïƒ      1
                                                                             b=1 Î¸b âˆ’ B
                                                                                        1
                                                                                           b=1 Î¸b


                                                         Intervalle de confiance, biais, quantiles,
                                                       tests dâ€™hypotheÌ€ses, etc.

         AggreÌgations de Classifieurs                                                                31 / 48
ConsideÌrations sur le bootstrap

          Le ne remplace pas L.
          Le est utiliseÌ pour estimer des parameÌ€tres dâ€™un estimateur baseÌ sur L ! !

  Le bootstrap ne peut pas sâ€™appliquer si :
    EÌchantillon L trop faible
    DonneÌes trop bruiteÌes
    Dans le cas de deÌpendances structurelles dans L (par exemple, seÌries
    temporelles, probleÌ€mes 2D,etc.)


  Comment choisir B = Lb ?


  Un grand nombre de versions leÌgeÌ€rements diffeÌrentes.
Par exemple, Jackknife : extraire les n sous-listes de L de taille n âˆ’ 1.


       AggreÌgations de Classifieurs                                                32 / 48
MeÌthodologie et aggreÌgations
                                                                                    algo i




                                       Apprentissage
                                                              Î a
                                                                                  Cbi
                                                              Î v
                                                                     Validation
    Base




                                                                                  Cbâˆ—
                                                       Test


                                                               Evaluation

 Est-ce que choisir Cbâˆ— parmi les Cbi a un sens ?
 Y a-t-il vraiment un â€™meilleurâ€™ ?
       AggreÌgations de Classifieurs                                                    33 / 48
AggreÌgations

Soit un certain nombre de classifieurs (Cbi )iâˆˆI pour une meÌ‚me classification C .
Chaque Ci est plus ou moins preÌcis. Ils sont eÌgalement plus ou moins stables.

StabiliteÌ
Un classifieur Cb est instable quand de petites modifications dans Î a peuvent entraÄ±Ì‚ner de
grandes modifications dans la classification proposeÌe par Cb.

Les statistiques nous ont appris que moyenner les reÌsultats est un bon moyen de reÌduire
la variance (lâ€™instabiliteÌ).
Est-il possible de combiner les (Cbi )iâˆˆI de manieÌ€re aÌ€ obtenir un meilleur classifieur ?

AggreÌgation majoritaire
En consideÌrant chaque Cbi comme un â€™expertâ€™, une manieÌ€re dâ€™aggreÌger leurs avis est de
les faire voter et de choisir lâ€™avis majoritaire :

                                        Cbmaj (x) = arg max   Cbi (x) = c, i âˆˆ I
                                                  câˆˆ{ â—‹,
                                                      + â—‹}
                                                         -




        AggreÌgations de Classifieurs                                                 34 / 48
AggreÌgations avec poids
On peut raffiner lâ€™aggreÌgation majoritaire en introduisant des poids associeÌs aÌ€
lâ€™expert.

AggreÌgation majoritaire avec poids
                                                                             P
Pour chaque Cbi , on note wi son poids associeÌ,alors Cbw (x) = arg max                    wi
                                                              câˆˆ{ â—‹,
                                                                  + â—‹}
                                                                     - (       iâˆˆI
                                                                                       )
                                                                           Cbi (x)=c



Pour fixer les poids, on sâ€™attend aÌ€ ce quâ€™un expert qui donne souvent la bonne
reÌponse ait un poids â€™eÌleveÌâ€™.

  Adaptation des poids
                                           Si Î² = 0, algorithme dit de Halving.
  Data : Î² âˆˆ [0, 1)                        Si Î² = 12 , avec k le nbr minimal dâ€™erreurs
1 âˆ€i, wi = 1                               faites par un Cbi sur Î a , n le nombre de Cbi ,
2 foreach Ï€ âˆˆ Î a do                        et M le nombre dâ€™erreurs faite par Cw ,
3     if Cbi (Ï€) Ì¸= C (Ï€) then
4          wi = Î² Â· w i                               M â‰¤ 2.4 (k + log2 (n))



        AggreÌgations de Classifieurs                                                           35 / 48
Bagging
                                                                                               (i)
Pour le bagging, on consideÌ€re quâ€™il faut constituer des ensembles Î a speÌcifiques
pour estimer chaque classifieur Cbi (qui peuvent eÌ‚tre alors de meÌ‚me type) et
moyenner les reÌsultats : cÌ§a ressemble aÌ€ du bootstrap.

Bootstrap aggregating
         
      (i)
Soit Î a                  une famille dâ€™eÌchantillons bootstrap (avec remise), alors :
                  iâˆˆI


                  âˆ€i âˆˆ I, Cbi est estimeÌ sur Î (i)
                                               a              et     Cbagging (x) = Cbmaj (x)


Si les Cbi sont effectivement des classifieurs de meÌ‚me type, heuristiquement, il doivent eÌ‚tre instable afin que
chaque eÌchantillon bootstrap fournisse un classifieur diffeÌrent.


Convergence et geÌneÌralisation
      Pas de preuve de convergence.
      Pas de borne connue pour lâ€™erreur de geÌneÌralisation.
      En pratique, souvent excellents reÌsultats (XGBoost, Random Forest).
          AggreÌgations de Classifieurs                                                                       36 / 48
ModeÌ€les additifs

  Dans les classifieurs majoritaires aÌ€ poids, la classification sâ€™effecture comme
espeÌrance de plusieurs classifieurs, eÌventuellement pondeÌreÌs.

 Il sâ€™agit donc de choisir chaque classifieur et son poids associeÌ de manieÌ€re aÌ€
ameÌliorer le reÌsultat global.

  ideÌe : au lieu de construire les classifieurs â€™indeÌpendammentâ€™, il serait pertinent
de construire increÌmentalement chaque classifieur afin quâ€™il sâ€™inteÌresse
particulieÌ€rement aux points pour lâ€™instant mal classeÌs.

  ideÌe : cÌ§a pourrait marcher meÌ‚me avec des classifieurs faibles.

â½ DeÌfinition (Classifieur faible (weak classifier))
Un classifieur faible est un classifieur a peine plus preÌcis que le classifieur aleÌatoire.


  Câ€™est le principe des algorithmes de boosting.

        AggreÌgations de Classifieurs                                                  37 / 48
Boosting : principes

principe : un nouveau classifieur doit se concentrer sur les eÌleÌments de Î a mal
classeÌs pour lâ€™instant.

Boosting scheÌmatique
  1   Affecter un poids aÌ€ chaque Ï€ âˆˆ Î a
  2   Proposer un classifieur faible (â€œxi <...â€, â€œreÌ€gle dâ€™orâ€œ, â€rule of thumbâ€œ)
  3   Modifier les poids pour tenir compte de ce nouveau classifier
  4   Recommencer T fois les 2 derniers points.
  5   Combiner tous les classifieurs dans Cbboosting


Deux questions (au moins) :
      Comment mettre aÌ€ jour les poids ?
      Comment combiner correctement tous ces classifieurs ?


        AggreÌgations de Classifieurs                                              38 / 48
    Erreur en geÌneÌralisation
                                                            
    On rappelle : eP (Cb) = EP C (x) Ì¸= Cb(x) ouÌ€ P probabiliteÌ sur Î .

       En particulier, si Cb est un classifieur faible, e(Cb) â‰¤ 21 âˆ’ Î³, Î³ > 0 : Cb est un peu meilleur que le classifieur
    aleÌatoire qui se trompe une fois sur deux.                                                    P
       Pour Î a = {x1 , Â· Â· Â· , xn }, on notera D(xi ) le poids associeÌ aÌ€ xi . D(.) probabiliteÌ ( i D(xi ) = 1).


    AdaBoost (Freund & Schapire, 1995)
1 âˆ€xi , D1 (x1 ) = n1
2 soit Cb1 un premier classifieur faible
3 repeat
                                            Ïµt
4      Calculer Ïµt = eDt (Cbt ) et Î²t = 1âˆ’Ïµ       <1
                                              t

                       Dt (xi )      si Ct (xi ) Ì¸= C (xi )
                                        b
5      Dt+1 (xi ) âˆ
                       Î²t Â· Dt (xi ) sinon
6      Estimer Ct+1 un classifieur faible minimisant eD
                  b
                                                                              t+1

7 until condition dâ€™arreÌ‚t (T fois par exemple);                                          Î±t en fonction de eDt (Cbt )
                     P b
                    
8 Cboosting (x) = Ïƒ     Î±t Ct (x) avec Î±t = 21 log Î²1t
                                    t


              AggreÌgations de Classifieurs                                                                         39 / 48
AdaBoost : un exemple (â€A Tutorial On Boostingâ€œ, Freung,Y. & Schapire,R.)




       AggreÌgations de Classifieurs                                   40 / 48
AdaBoost : un exemple (â€A Tutorial On Boostingâ€œ, Freung,Y. & Schapire,R.)




                                              1     1 âˆ’ Ïµ1
                                       Î±1 =     log
                                              2       Ïµ1

       AggreÌgations de Classifieurs                                   41 / 48
AdaBoost : un exemple (â€A Tutorial On Boostingâ€œ, Freung,Y. & Schapire,R.)




                                              1     1 âˆ’ Ïµ2
                                       Î±2 =     log
                                              2       Ïµ2


       AggreÌgations de Classifieurs                                   42 / 48
AdaBoost : un exemple (â€A Tutorial On Boostingâ€œ, Freung,Y. & Schapire,R.)




                                              1     1 âˆ’ Ïµ3
                                       Î±3 =     log
                                              2       Ïµ3


       AggreÌgations de Classifieurs                                   43 / 48
AdaBoost : un exemple (â€A Tutorial On Boostingâ€œ, Freung,Y. & Schapire,R.)




       AggreÌgations de Classifieurs                                   44 / 48
bagging vs boosting

Les 2 meÌthodes ont en commun une augmentation de la stabiliteÌ du classifieur, au
prix dâ€™un temps de calcul plus important. Voici quelques geÌneÌraliteÌs aÌ€ ne pas
prendre pour veÌriteÌs absolues :
    Bagging est souvent plus rapide que boosting.
    A contrario, la reÌduction dâ€™erreur est moindre pour bagging.
    Bagging est une meÌthode qui fonctionne avec des ensembles de classifieurs
    â€™raisonnablesâ€™ mais peu stables (arbres de deÌcisions par exemple).
    Boosting utilise des classifieurs treÌ€s simples et donc treÌ€s faibles.
    AdaBoost nâ€™a plus quâ€™un parameÌ€tre : le nombre de classifieurs que lâ€™on veut
    mettre.
    Boosting est treÌ€s sensible au bruit i.e. aÌ€ un grand nombre de donneÌes mal
    classeÌes (puisquâ€™il va leur donner un grand poids).
    Comme les classifieurs faibles ont un biais important, on peut consideÌrer le
    boosting comme une meÌthode de reÌduction du biais.


       AggreÌgations de Classifieurs                                           45 / 48
Boosting : erreur en geÌneÌralisation

Que se passe-t-il si on augmente beaucoup le nombre de classifieurs faibles ?
  GeÌneÌralement, on sâ€™attend aÌ€ :
       Erreur dâ€™apprentissage (sur Î a ) qui
       tend vers 0.
       Erreur en geÌneÌralisation qui
       remonte (sur-apprentissage,
       overfitting)
                                                    Comportement asymptotique des erreurs


ExpeÌrimentalement, pour AdaBoost

                                        Lâ€™erreur de test (meilleure
                                        approximation de lâ€™erreur en
                                        geÌneÌralisation) nâ€™augmente pas !
                                        MeÌ‚me quand lâ€™erreur dâ€™apprentissage
                                        est nulle !

       AggreÌgations de Classifieurs                                                   46 / 48
Boosting et marges
                                                          P
                                                                       
Le boosting prend la forme : Cboosting (x) = Ïƒ                Î±t Cbt (x) avec Î±t = log Î²1t .
                                                          t
La marge est deÌfinie par min (f (x) Â· C (x)).
                                       xâˆˆÎ a
On se souvient eÌgalement quâ€™une marge importante indique une robustesse du
classifieur, et donc une plus faible erreur en geÌneÌralisation.

Boosting et marge


                                              Quand lâ€™erreur de test ne diminue plus,
                                              on observe une augmentation de la
                                              marge.
                                              Ce comportement est theÌoriquement
                                              prouvable.




       AggreÌgations de Classifieurs                                                       47 / 48
ReÌsumeÌ




   Boosting et bagging combinent les reÌsultats dâ€™ensembles de classifieurs.
   A priori, ces meÌthodes ameÌliorent les reÌsultats en diminuant le biais ou la
   variance des classifieurs.
   Bagging est principalement une meÌthode de reÌduction de la variance, utiliseÌ
   avec des classifieurs aÌ€ part entieÌ€res.
   Boosting se concentre sur les cas particuliers difficiles. Il reÌduit principalement
   le biais et augmente la marge. Mais il est sensible au bruit.




     AggreÌgations de Classifieurs                                                  48 / 48
